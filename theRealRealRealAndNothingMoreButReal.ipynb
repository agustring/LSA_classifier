{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_D47c4SuCSJp"
   },
   "source": [
    "\n",
    "# Data\n",
    "\n",
    "Buscamos primero la data que dejamos por github, hay banda asi que eso nos va a llevar unas lineas.\n",
    "Todo disponible en: https://github.com/agustring/LSA_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edn-4joFCI9q",
    "outputId": "0eae345c-bd81-45d8-9f81-769a27c4beac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 43)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "l = '001'\n",
    "u = '004'\n",
    "s = '004'\n",
    "url = 'https://raw.githubusercontent.com/agustring/LSA_classifier/main/preproc%20data/{}_{}_{}_pre.json?token=ARECJQ4LDX673DAOGWXLV5TBSKZ5W'.format(l, u, s)\n",
    "\n",
    "df = pd.read_json(url)\n",
    "df.shape #Forma de un video (None,43,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfdSbhdJRdqD",
    "outputId": "0b1107a1-bc7c-4d76-ba17-7f3a940c7f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todo en minutos:  6.535082240899404\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import urllib.request, json \n",
    "\n",
    "t1 = time.time()\n",
    "x=0\n",
    "\n",
    "dataset = []\n",
    "data_for_visual = np.zeros(750,dtype=object)\n",
    "\n",
    "def help_the_norman(df):\n",
    "  a = df\n",
    "  min_i = 0\n",
    "  min_j = 0\n",
    "  for i in range(len(df)):\n",
    "    j = 10\n",
    "    if df[i][j][0] < 1e-6:\n",
    "      min_i = i\n",
    "    if df[i][j+20][0] < 1e-6:\n",
    "      min_j = i\n",
    "    if min_j+1 > len(df[i][j]):\n",
    "      min_j = 0\n",
    "    if min_i+1 > len(df[i][j]):\n",
    "      min_i = 0\n",
    "  #print(min_i)\n",
    "\n",
    "  for i in range(int(min_i)):\n",
    "    for j in range(22):\n",
    "      a[i][j][0] = df[min_i+1][j][0]\n",
    "      a[i][j][1] = df[min_i+1][j][1]\n",
    "\n",
    "  for i in range(int(min_j)):\n",
    "    for j in range(22,42):\n",
    "      a[i][j][0] = df[min_j+1][j][0]\n",
    "      a[i][j][1] = df[min_j+1][j][1]\n",
    "\n",
    "  return a\n",
    "\n",
    "def norman(df):\n",
    "  a = df\n",
    "  min_x = df[0][0][0]\n",
    "  max_x = df[0][0][0]\n",
    "  min_y = df[0][0][1]\n",
    "  max_y = df[0][0][1]\n",
    "  for i in range(len(df)):\n",
    "    for j in range(len(df[i])):\n",
    "      if df[i][j][0] < min_x:\n",
    "        min_x = df[i][j][0]\n",
    "      if df[i][j][0] > max_x:\n",
    "        max_x = df[i][j][0]\n",
    "      if df[i][j][1] < min_y:\n",
    "        min_y = df[i][j][1]\n",
    "      if df[i][j][1] > max_y:\n",
    "        max_y = df[i][j][1]\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    for j in range(len(df[i])):\n",
    "      b = (max_x-min_x)\n",
    "      c = (max_y-min_y)\n",
    "      if b > 1e-6:\n",
    "        a[i][j][0] = (df[i][j][0]-min_x)/b\n",
    "        a[i][j][1] = (df[i][j][1]-min_y)/c\n",
    "      else:\n",
    "        a[i][j][0] = 0\n",
    "        a[i][j][1] = 0\n",
    "  return a\n",
    "\n",
    "for user in range(1,11): #1,11\n",
    "  u = '00'+str(user)\n",
    "      \n",
    "  if user>9:\n",
    "      u = '0'+str(user)\n",
    "\n",
    "  for label in range(1,16): #1,16\n",
    "      \n",
    "      l = '00'+str(label)\n",
    "      \n",
    "      if label>9:\n",
    "          l = '0'+str(label)\n",
    "          \n",
    "      for sample in range(1,6): #1,6\n",
    "          t2 = time.time()\n",
    "          s = '00'+str(sample)\n",
    "          \n",
    "          url = 'https://raw.githubusercontent.com/agustring/LSA_classifier/main/preproc%20data2/{}_{}_{}_pre.json?token=ARECJQ4LDX673DAOGWXLV5TBSKZ5W'.format(u, l, s)\n",
    "          \n",
    "          with urllib.request.urlopen(url) as url2:\n",
    "              df = json.loads(url2.read().decode())\n",
    "          df = norman(df)\n",
    "          df = help_the_norman(df)\n",
    "          data_struct = np.array([[0 for i in range(2*42)] for j in range(150)], dtype=float)\n",
    "          for i in range(len(df)):\n",
    "              p=0\n",
    "              for j in range(0,42,2):\n",
    "                  data_struct[i+(150-len(df)),j] = df[i][p][0]\n",
    "                  data_struct[i+(150-len(df)),j+42] = df[i][p][1]\n",
    "                  #data_struct[i,j+2] = df[i][p][2]\n",
    "                  p+=1\n",
    "          dataset.append(data_struct)\n",
    "          data_for_visual[x] = np.array(df)\n",
    "\n",
    "print('Todo en minutos: ',(time.time()-t1)/60)\n",
    "            \n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "B5jymXBF1ooI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.5108453 0.        0.5006721 ... 0.        0.6351324 0.       ]\n",
      " [0.5108453 0.        0.5006721 ... 0.        0.6351324 0.       ]\n",
      " [0.5108453 0.        0.5006721 ... 0.        0.6351324 0.       ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(dataset[3])\n",
    "print(dataset[3][1])\n",
    "print(dataset[3][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "o8JDND0Md6WR"
   },
   "outputs": [],
   "source": [
    "labels = np.zeros(len(dataset),dtype=int)\n",
    "x=-1\n",
    "for k in range(0,len(dataset),5):\n",
    "    x+=1\n",
    "    if x==15:\n",
    "        x=0\n",
    "    labels[k:k+5] = int(x)\n",
    "    \n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QkFJD3kASKXJ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tst = .5\n",
    "index = []\n",
    "index_lbl = []\n",
    "\n",
    "for i in range(0,int(len(dataset)),5):\n",
    "  index_lbl.append(i+2)\n",
    "  index.append(i)\n",
    "  index.append(i+1)\n",
    "  index.append(i+3)\n",
    "  index.append(i+4)\n",
    "\n",
    "random.shuffle(index)\n",
    "random.shuffle(index_lbl)\n",
    "\n",
    "X_train = dataset[index]\n",
    "y_train = labels[index]\n",
    "x_test = dataset[index_lbl]\n",
    "y_test = labels[index_lbl]\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOtfVmSaNzQv"
   },
   "source": [
    "# Ahora si ðŸ˜ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF0SOgbkOdrl"
   },
   "source": [
    "Esto es viejo, ahora es `input_shape=(750, 150, 43* 2)` \n",
    "\n",
    "`batch_input_shape=(750, None, 43, 3)` \n",
    "\n",
    "Bueno al final no me dejo poner 750\n",
    "\n",
    "Los 750 son los videos.\n",
    "\n",
    "El None la longitud de cada uno (indeterminada).\n",
    "\n",
    "El 43 los atributos.\n",
    "\n",
    "El ultimo 3 las dimensiones de la mano.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2HYxNrCd4T5",
    "outputId": "7177d32b-9384-4584-f1bf-40a4a7a9b1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 150, 84)\n",
      "(600,)\n",
      "(150, 150, 84)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWexhWK1gYLk"
   },
   "outputs": [],
   "source": [
    "os.listdir(checkpoint_dir)\n",
    "\n",
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sMH-sSIh-Eb"
   },
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') \n",
    "\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM, Flatten, Embedding, Input, Conv1D,MaxPooling1D,Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, SGD, RMSprop\n",
    "from keras import metrics\n",
    "import os\n",
    "\n",
    "checkpoint_path = \"training_1/lsa_classifier.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=False)\n",
    "\n",
    "history = []\n",
    "with tpu_strategy.scope():\n",
    "  model = Sequential()\n",
    "model.add(Input((150,84)))\n",
    "model.add(Bidirectional(LSTM(84*7, activation=\"tanh\",recurrent_activation=\"sigmoid\", input_shape=(150,420),return_sequences=False)))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "opt = Adamax(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\")\n",
    "#opt = RMSprop(learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False, name=\"RMSprop\")\n",
    "#opt = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#with tf.device('/device:GPU:0'):\n",
    "\n",
    "history.append(model.fit(X_train, y_train, \n",
    "                          epochs=1500, batch_size=10,\n",
    "                          validation_data=(x_test, y_test)))\n",
    "                          #callbacks=[cp_callback]))\n",
    "  \n",
    "y_pred = model.predict(x_test)\n",
    "#with tf.device('/device:GPU:0'):\n",
    "#model.add(Conv1D(filters=84, kernel_size=3, activation='relu', input_shape=(150,84)))\n",
    "#model.add(Conv1D(filters=84*10, kernel_size=3, activation='relu'))\n",
    "#model.add(Conv1D(filters=84*50, kernel_size=3, activation='relu'))\n",
    "#model.add(Conv1D(filters=84*150, kernel_size=3, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(MaxPooling1D(pool_size=3))\n",
    "#model.add(Bidirectional(layers.LSTM(84*5,  activation=\"tanh\",recurrent_activation=\"sigmoid\", input_shape=(150,84),return_sequences=True)))\n",
    "#model.add(LSTM(84*5,  activation=\"tanh\",recurrent_activation=\"sigmoid\", input_shape=(150,84),return_sequences=True))\n",
    "\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "#opt = RMSprop(learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False, name=\"RMSprop\")\n",
    "#opt = Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\\\n",
    "#opt = SGD(learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhCTH_4sv3_h",
    "outputId": "c4bba691-0121-49ac-fcce-83e17e035fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2507070e-03 8.7476394e-05 4.6626028e-06 7.8377007e-03 9.1016853e-05\n",
      " 4.2175705e-04 1.7380656e-03 5.6926045e-03 1.7873926e-02 9.4471496e-01\n",
      " 8.7784556e-06 2.5980317e-03 1.6878217e-02 3.4460006e-04 4.5748890e-04]\n",
      "True\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "i=33\n",
    "print(y_pred[i])\n",
    "print(y_pred[i].max() == (y_pred[i][y_test[i]]))\n",
    "print(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9bxEosxWMYk"
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in range(len(y_pred)):\n",
    "  pred.append(y_pred[i].max() == (y_pred[i][y_test[i]]))\n",
    "print(np.count_nonzero(pred)/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zqn3FR3YSIhY",
    "outputId": "a9b165e2-08fe-415d-9db6-0ececc2d73dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcdba6cbc50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "vQ-_pUqrBxTH",
    "outputId": "2b920e07-54b1-41d0-949e-adc14cb89bee"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(history)+1)\n",
    "fig.set_size_inches(10,8*len(history)+1)\n",
    "fig.suptitle('Varias muestras')\n",
    "\n",
    "for video_num in range(len(history)):\n",
    "  axs[video_num].set_title(\"Epochs=40; LSTM nodes: \"+str((video_num+7)*84))\n",
    "  axs[video_num].set_xlabel('x')\n",
    "  axs[video_num].set_ylabel('y')\n",
    "  #axs[video_num].axis(xmin=0,xmax=1,ymin=0,ymax=1)\n",
    "  axs[video_num].plot(history[video_num].history['accuracy'])\n",
    "  axs[video_num].plot(history[video_num].history['val_accuracy'])\n",
    "\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "LwKGp8aHwfjj",
    "outputId": "e6f29a1b-9e48-4bb5-bb08-2a3175dbc12f"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtRgl_pNwkjs"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "theRealRealRealAndNothingMoreButReal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
